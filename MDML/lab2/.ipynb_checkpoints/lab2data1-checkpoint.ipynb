{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pipelinehelper'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23064/1238753678.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnaive_bayes\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipeline\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpipelinehelper\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPipelineHelper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pipelinehelper'"
     ]
    }
   ],
   "source": [
    "# This is second part, I need to repeat 8 first steps with new dataset\n",
    "# imports\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from pipelinehelper import PipelineHelper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Sample code number  Clump Thickness  Uniformity of Cell Size  \\\n",
      "0             1000025                5                        1   \n",
      "1             1002945                5                        4   \n",
      "2             1015425                3                        1   \n",
      "3             1016277                6                        8   \n",
      "4             1017023                4                        1   \n",
      "5             1017122                8                       10   \n",
      "6             1018099                1                        1   \n",
      "7             1018561                2                        1   \n",
      "8             1033078                2                        1   \n",
      "9             1033078                4                        2   \n",
      "\n",
      "   Uniformity of Cell Shape  Marginal Adhesion  Single Epithelial Cell Size  \\\n",
      "0                         1                  1                            2   \n",
      "1                         4                  5                            7   \n",
      "2                         1                  1                            2   \n",
      "3                         8                  1                            3   \n",
      "4                         1                  3                            2   \n",
      "5                        10                  8                            7   \n",
      "6                         1                  1                            2   \n",
      "7                         2                  1                            2   \n",
      "8                         1                  1                            2   \n",
      "9                         1                  1                            2   \n",
      "\n",
      "   Bare Nuclei  Bland Chromatin  Normal Nucleoli  Mitoses  Class  \n",
      "0            1                3                1        1      2  \n",
      "1           10                3                2        1      2  \n",
      "2            2                3                1        1      2  \n",
      "3            4                3                7        1      2  \n",
      "4            1                3                1        1      2  \n",
      "5           10                9                7        1      4  \n",
      "6           10                3                1        1      2  \n",
      "7            1                3                1        1      2  \n",
      "8            1                1                1        5      2  \n",
      "9            1                2                1        1      2  \n"
     ]
    }
   ],
   "source": [
    "# get dataset\n",
    "dataset = pd.read_csv('Data1.csv')\n",
    "print(dataset.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I got a wise advice to actually START using np arrays instead of dataframes.\n",
    "X = np.array(dataset.drop('Class', axis= 1))\n",
    "y = np.array(dataset['Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another advice I got is to train and fit the model before splitting it into train and test variables\n",
    "standard_scaler = StandardScaler()\n",
    "scaled_matrix = standard_scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into tran and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_matrix, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 4, 4, 2, 4, 2, 4, 4, 2, 2, 4, 4, 2, 2, 4, 2, 2, 2, 4, 2, 2, 2,\n",
       "       4, 2, 2, 2, 2, 2, 4, 4, 2, 2, 4, 4, 4, 4, 2, 2, 4, 2, 2, 2, 4, 4,\n",
       "       2, 4, 4, 4, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 4, 4, 2, 2,\n",
       "       2, 4, 2, 4, 2, 2, 2, 2, 4, 2, 2, 4, 4, 2, 4, 2, 2, 2, 2, 2, 4, 4,\n",
       "       2, 4, 2, 2, 4, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 4, 2, 2, 4, 2, 2, 2, 2, 2, 4, 2, 4, 2, 2, 2, 4, 4, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create SVC, make a prediction\n",
    "svc_classifier = SVC(kernel='linear', random_state = 0)\n",
    "svc_classifier.fit(X_train, y_train)\n",
    "svc_prediction = svc_classifier.predict(X_test)\n",
    "svc_prediction\n",
    "# well, not exactly the way to see the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[91  3]\n",
      " [ 2 41]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.98      0.97      0.97        94\n",
      "           4       0.93      0.95      0.94        43\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.96      0.96      0.96       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "0.9635036496350365\n"
     ]
    }
   ],
   "source": [
    "# compare prediction with actual results\n",
    "print(confusion_matrix(y_test,svc_prediction))\n",
    "print(classification_report(y_test,svc_prediction))\n",
    "# results differ from one predict to another, but precision in bigger than recall most of the times\n",
    "# and in general looks good enough\n",
    "# \n",
    "# Also this is worth mentioning that without 'fit and transform' function before splitting data into\n",
    "# train and test I was getting worse results than here\n",
    "print(accuracy_score(y_test, svc_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92753623 0.97101449 0.95652174 0.94117647 0.98529412 0.97058824\n",
      " 0.95588235 1.         0.97058824 0.98529412]\n",
      "0.9663895993179882\n"
     ]
    }
   ],
   "source": [
    "# now we will cross validate the result to see if we can reach more accuracy\n",
    "scores = cross_val_score(svc_classifier, scaled_matrix, y, cv=10)\n",
    "print(scores)\n",
    "print(scores.mean())\n",
    "# Ugh, it seems we were just very lucky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set: {'C': 1, 'kernel': 'linear'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.969 (+/-0.028) for {'C': 0.25, 'kernel': 'linear'}\n",
      "0.965 (+/-0.043) for {'C': 0.25, 'kernel': 'rbf'}\n",
      "0.969 (+/-0.028) for {'C': 0.5, 'kernel': 'linear'}\n",
      "0.965 (+/-0.043) for {'C': 0.5, 'kernel': 'rbf'}\n",
      "0.969 (+/-0.028) for {'C': 0.75, 'kernel': 'linear'}\n",
      "0.965 (+/-0.043) for {'C': 0.75, 'kernel': 'rbf'}\n",
      "0.971 (+/-0.027) for {'C': 1, 'kernel': 'linear'}\n",
      "0.967 (+/-0.040) for {'C': 1, 'kernel': 'rbf'}\n",
      "\n",
      "Best results found with 0.971 mean and parameters {'C': 1, 'kernel': 'linear'}\n",
      "classification report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.98      0.97      0.97        94\n",
      "           4       0.93      0.95      0.94        43\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.96      0.96      0.96       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# next step is grid search\n",
    "# set C parameters and kernel\n",
    "param_grid = [\n",
    "  {'C': [0.25, 0.5, 0.75, 1], 'kernel': ['linear','rbf']}\n",
    " ]\n",
    "\n",
    "grid_search_result = GridSearchCV(svc_classifier, param_grid, scoring=\"accuracy\", n_jobs= -2)\n",
    "grid_search_result.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"Best parameters set found on development set: \"+str(grid_search_result.best_params_))\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = grid_search_result.cv_results_[\"mean_test_score\"]\n",
    "stds = grid_search_result.cv_results_[\"std_test_score\"]\n",
    "best_result = {}\n",
    "mean_zero = 0\n",
    "# zip to loop through several lists\n",
    "for mean, std, params in zip(means, stds, grid_search_result.cv_results_[\"params\"]):\n",
    "    if(mean_zero < mean):\n",
    "        mean_zero = mean\n",
    "        best_result['mean'] = mean\n",
    "        best_result['params'] = params\n",
    "    print(\"%0.3f (+/-%0.03f) for %s\" % (mean, std * 2, params))\n",
    "print()\n",
    "print('Best results found with %0.3f mean and parameters %s' % (best_result['mean'], best_result['params']))\n",
    "# to be fair, all 3 rbf kernels showed the same result\n",
    "print(\"classification report:\")\n",
    "print()\n",
    "y_true, y_pred = y_test, grid_search_result.predict(X_test)\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>Now I need to implement a lot of different models</br>\n",
    "1. Logistic\tRegression\n",
    "2. Decision\tTree Classifier\n",
    "3. Random\tForest\tClassifier\t(with\tnb_trees\t=\t10)\n",
    "4. K- Nearest\tNeighbors (K-NN)\n",
    "5. Naïve\tBayes\n",
    "6. Support\tVector\tMachine\t(SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.97 accuracy with std of 0.02\n"
     ]
    }
   ],
   "source": [
    "# 1. Logistic regression\n",
    "logistic_regression = LogisticRegression()\n",
    "logistic_regression.fit(X_train, y_train)\n",
    "prediction = logistic_regression.predict(X_test)\n",
    "scores = cross_val_score(logistic_regression, scaled_matrix, y, cv=10)\n",
    "print(\"%0.2f accuracy with std of %0.2f\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression  : confusion matrix \n",
      "[[92  2]\n",
      " [ 2 41]]\n",
      "LogisticRegression  : classification report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.98      0.98      0.98        94\n",
      "           4       0.95      0.95      0.95        43\n",
      "\n",
      "    accuracy                           0.97       137\n",
      "   macro avg       0.97      0.97      0.97       137\n",
      "weighted avg       0.97      0.97      0.97       137\n",
      "\n",
      "LogisticRegression  : 0.966 accuracy with std of 0.023\n",
      "\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
      "\n",
      "DecisionTreeClassifier  : confusion matrix \n",
      "[[92  2]\n",
      " [ 7 36]]\n",
      "DecisionTreeClassifier  : classification report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.93      0.98      0.95        94\n",
      "           4       0.95      0.84      0.89        43\n",
      "\n",
      "    accuracy                           0.93       137\n",
      "   macro avg       0.94      0.91      0.92       137\n",
      "weighted avg       0.93      0.93      0.93       137\n",
      "\n",
      "DecisionTreeClassifier  : 0.950 accuracy with std of 0.027\n",
      "\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
      "\n",
      "RandomForrestClassifier  : confusion matrix \n",
      "[[91  3]\n",
      " [ 2 41]]\n",
      "RandomForrestClassifier  : classification report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.98      0.97      0.97        94\n",
      "           4       0.93      0.95      0.94        43\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.96      0.96      0.96       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "RandomForrestClassifier  : 0.963 accuracy with std of 0.020\n",
      "\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
      "\n",
      "K-NearestNeighbors  : confusion matrix \n",
      "[[91  3]\n",
      " [ 4 39]]\n",
      "K-NearestNeighbors  : classification report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.96      0.97      0.96        94\n",
      "           4       0.93      0.91      0.92        43\n",
      "\n",
      "    accuracy                           0.95       137\n",
      "   macro avg       0.94      0.94      0.94       137\n",
      "weighted avg       0.95      0.95      0.95       137\n",
      "\n",
      "K-NearestNeighbors  : 0.966 accuracy with std of 0.024\n",
      "\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
      "\n",
      "NaiveBytes  : confusion matrix \n",
      "[[91  3]\n",
      " [ 2 41]]\n",
      "NaiveBytes  : classification report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.98      0.97      0.97        94\n",
      "           4       0.93      0.95      0.94        43\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.96      0.96      0.96       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "NaiveBytes  : 0.962 accuracy with std of 0.020\n",
      "\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
      "\n",
      "SupportVectorMachine  : confusion matrix \n",
      "[[91  3]\n",
      " [ 2 41]]\n",
      "SupportVectorMachine  : classification report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.98      0.97      0.97        94\n",
      "           4       0.93      0.95      0.94        43\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.96      0.96      0.96       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "SupportVectorMachine  : 0.966 accuracy with std of 0.020\n",
      "\n",
      "=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
      "\n",
      "Best regression model is LogisticRegression with accuracy 0.966 and std 0.023\n"
     ]
    }
   ],
   "source": [
    "# attempt to make it generic\n",
    "best_result = {}\n",
    "mean_zero = 0\n",
    "def generic_regression_model_execution(regression_model, regression_model_name):\n",
    "    global mean_zero\n",
    "    global best_result\n",
    "    regression_model.fit(X_train, y_train)\n",
    "    prediction = regression_model.predict(X_test)\n",
    "    print(regression_model_name,\" : confusion matrix \")\n",
    "    print(confusion_matrix(y_test, prediction))\n",
    "    print(regression_model_name,\" : classification report \")\n",
    "    print(classification_report(y_test, prediction))\n",
    "    scores = cross_val_score(regression_model, scaled_matrix, y, cv=10)\n",
    "    mean = scores.mean()\n",
    "    std = scores.std()\n",
    "    if(mean_zero < mean):\n",
    "        mean_zero = mean\n",
    "        best_result['regression_model_name'] = regression_model_name\n",
    "        best_result['accuracy'] = mean\n",
    "        best_result['std'] = std\n",
    "    print(regression_model_name,\" : %0.3f accuracy with std of %0.3f\" % (mean, std))\n",
    "    print()\n",
    "    print('=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-')\n",
    "    print()\n",
    "    \n",
    "list_of_regression_models = {}\n",
    "list_of_regression_models['LogisticRegression']=LogisticRegression()\n",
    "list_of_regression_models['DecisionTreeClassifier']=DecisionTreeClassifier()\n",
    "list_of_regression_models['RandomForrestClassifier']=RandomForestClassifier(n_estimators=10)\n",
    "list_of_regression_models['K-NearestNeighbors']=KNeighborsClassifier()\n",
    "list_of_regression_models['NaiveBytes']=GaussianNB()\n",
    "list_of_regression_models['SupportVectorMachine']=SVC()\n",
    "for key, value in list_of_regression_models.items():\n",
    "    generic_regression_model_execution(value, key)\n",
    "print(\"Best regression model is %s with accuracy %0.3f and std %0.3f\" % (best_result['regression_model_name'],\n",
    "                                                                         best_result['accuracy'],\n",
    "                                                                         best_result['std']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so, next two steps ask both to choose best the best model based on grid search and to find best hyper parameters for it\n",
    "# luckily for me, a friend showed me similar generic way to use GridSearch\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2b355ee983f23f4d0b28e90ea45b33537f29c12390fbee61533ba394cb277947"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
