{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Laboratory work nr. 2 part 1</h1>\n",
    "<p>Scebec Mihai, IS-211M</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this laboratory we are working with two different datasets, so I decided to divide the work into two different files.\n",
    "I will start with the imports, getting the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just to make things clear - we have 2 different datasets, so I'd like to have them in separate ipynb files\n",
    "# imports\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Age  EstimatedSalary  Purchased\n",
      "0   19            19000          0\n",
      "1   35            20000          0\n",
      "2   26            43000          0\n",
      "3   27            57000          0\n",
      "4   19            76000          0\n",
      "5   27            58000          0\n",
      "6   27            84000          0\n",
      "7   32           150000          1\n",
      "8   25            33000          0\n",
      "9   35            65000          0\n"
     ]
    }
   ],
   "source": [
    "# get dataset\n",
    "dataset = pd.read_csv('Social_Network_Ads.csv')\n",
    "print(dataset.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I got a wise advice to actually START using np arrays instead of dataframes.\n",
    "X = np.array(dataset[['Age', 'EstimatedSalary']])\n",
    "y = np.array(dataset['Purchased'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another advice I got is to train and fit the model before splitting it into train and test variables\n",
    "standard_scaler = StandardScaler()\n",
    "scaled_matrix = standard_scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into tran and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_matrix, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One wise friend of mine told me to scale dataset before splitting and working with it. He was absolutely right. This, together with working with numpy arrays instead of dataframes sped up the work greatly. Before I had freezing PC and lagging ipy kernel, now it takes seconds to process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create SVC, make a prediction\n",
    "svc_classifier = SVC(kernel='linear', random_state = 0)\n",
    "svc_classifier.fit(X_train, y_train)\n",
    "svc_prediction = svc_classifier.predict(X_test)\n",
    "svc_prediction\n",
    "# well, not exactly the way to see the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[50  4]\n",
      " [11 15]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.93      0.87        54\n",
      "           1       0.79      0.58      0.67        26\n",
      "\n",
      "    accuracy                           0.81        80\n",
      "   macro avg       0.80      0.75      0.77        80\n",
      "weighted avg       0.81      0.81      0.80        80\n",
      "\n",
      "0.8125\n"
     ]
    }
   ],
   "source": [
    "# compare prediction with actual results\n",
    "print(confusion_matrix(y_test,svc_prediction))\n",
    "print(classification_report(y_test,svc_prediction))\n",
    "# results differ from one predict to another, but precision in bigger than recall most of the times\n",
    "# and in general looks good enough\n",
    "# \n",
    "# Also this is worth mentioning that without 'fit and transform' function before splitting data into\n",
    "# train and test I was getting worse results than here\n",
    "print(accuracy_score(y_test, svc_prediction))\n",
    "# 0.9 accuracy seems surprisingly high, I got way worse results last attempt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I see that from 80 values we are getting 15 of them wrong, this seems pretty ok-ish already, but, obviously, not perfect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.675 0.675 0.975 0.95  1.    0.875 0.8   0.775 0.8   0.675]\n",
      "0.82\n"
     ]
    }
   ],
   "source": [
    "# now we will cross validate the result to see if we can reach more accuracy\n",
    "scores = cross_val_score(svc_classifier, scaled_matrix, y, cv=10)\n",
    "print(scores)\n",
    "print(scores.mean())\n",
    "# Ugh, it seems we were just very lucky"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation shows that what I got above is semi what I can expect to get from this model everytime, but, ofc, even cross validation gave me different results from try to try. Some of them were above .90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set: {'C': 0.5, 'kernel': 'rbf'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.834 (+/-0.081) for {'C': 0.25, 'kernel': 'linear'}\n",
      "0.900 (+/-0.051) for {'C': 0.25, 'kernel': 'rbf'}\n",
      "0.844 (+/-0.066) for {'C': 0.5, 'kernel': 'linear'}\n",
      "0.909 (+/-0.046) for {'C': 0.5, 'kernel': 'rbf'}\n",
      "0.844 (+/-0.079) for {'C': 0.75, 'kernel': 'linear'}\n",
      "0.909 (+/-0.046) for {'C': 0.75, 'kernel': 'rbf'}\n",
      "0.844 (+/-0.079) for {'C': 1, 'kernel': 'linear'}\n",
      "0.909 (+/-0.046) for {'C': 1, 'kernel': 'rbf'}\n",
      "\n",
      "Best results found with 0.909 mean and parameters {'C': 0.5, 'kernel': 'rbf'}\n",
      "classification report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93        54\n",
      "           1       0.85      0.88      0.87        26\n",
      "\n",
      "    accuracy                           0.91        80\n",
      "   macro avg       0.90      0.91      0.90        80\n",
      "weighted avg       0.91      0.91      0.91        80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# next step is grid search\n",
    "# set C parameters and kernel\n",
    "param_grid = [\n",
    "  {'C': [0.25, 0.5, 0.75, 1], 'kernel': ['linear','rbf']}\n",
    " ]\n",
    "\n",
    "grid_search_result = GridSearchCV(svc_classifier, param_grid, scoring=\"accuracy\", n_jobs= -2)\n",
    "grid_search_result.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"Best parameters set found on development set: \"+str(grid_search_result.best_params_))\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = grid_search_result.cv_results_[\"mean_test_score\"]\n",
    "stds = grid_search_result.cv_results_[\"std_test_score\"]\n",
    "best_result = {}\n",
    "mean_zero = 0\n",
    "# zip to loop through several lists\n",
    "for mean, std, params in zip(means, stds, grid_search_result.cv_results_[\"params\"]):\n",
    "    if(mean_zero < mean):\n",
    "        mean_zero = mean\n",
    "        best_result['mean'] = mean\n",
    "        best_result['params'] = params\n",
    "    print(\"%0.3f (+/-%0.03f) for %s\" % (mean, std * 2, params))\n",
    "print()\n",
    "print('Best results found with %0.3f mean and parameters %s' % (best_result['mean'], best_result['params']))\n",
    "# to be fair, all 3 rbf kernels showed the same result\n",
    "print(\"classification report:\")\n",
    "print()\n",
    "y_true, y_pred = y_test, grid_search_result.predict(X_test)\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For given parameters the code found best fit, that is .9 accuracy, pretty good. Second csv files seems to have better dataset for training than the first one.\n",
    "<p>\n",
    "As a small conclusion pre-processing incoming dataset and then further tuning the regression parameters can increase accuracy of the model by at least 10%, which is not a bad result, given we started with 80%. But we can do more using more regression types."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2b355ee983f23f4d0b28e90ea45b33537f29c12390fbee61533ba394cb277947"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
